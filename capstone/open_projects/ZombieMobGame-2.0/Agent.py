import random
import math

class LearningAgent(Agent):

	def __init__(self, ):
		super().__init__()     # Set the agent in the evironment 

		# Set parameters of the learning agent
		pass

	def reset():
		""" The reset function is called at the beginning of each trial.
            'testing' is set to True if testing trials are being used
            once training trials have completed. """

        # Select the destination as the new location to route to

        # Update epsilon using a decay function
        pass

    def build_state():
    	""" The build_state function is called when the agent requests data from the 
            environment."""

        # Set 'state' as a tuple of relevant data for the agent
        # When learning, check if the state is in the Q-table
        #   If it is not, create a dictionary in the Q-table for the current 'state'
        #   For each action, set the Q-value for the state-action pair to 0
        pass

    def get_maxQ(self, state):
    	""" The get_max_Q function is called when the agent is asked to find the
            maximum Q-value of all actions based on the 'state' """

        # Calculate the maximum Q-value of all actions for a given state
        pass

    def createQ(self, state):
        """ The createQ function is called when a state is generated by the agent. """

        # When learning, check if the 'state' is not in the Q-table
        # If it is not, create a new dictionary for that state
        #   Then, for each action available, set the initial Q-value to 0.0
        pass

    def choose_action():
    	""" The choose_action function is called when the agent is asked to choose
            which action to take, based on the 'state' the smartcab is in. """

        # Set the agent state and default action

        # When not learning, choose a random action
        # When learning, choose a random action with 'epsilon' probability
        #   Otherwise, choose an action with the highest Q-value for the current state
        pass

    def learn(self, state, action, reward):
    	""" The learn function is called after the agent completes an action and
            receives an award. This function does not consider future rewards 
            when conducting learning. """

        # When learning, implement the value iteration update rule
        #   Use only the learning rate 'alpha' (do not use the discount factor 'gamma')
        pass

    def update(self):
        """ The update function is called when a time step is completed in the 
            environment for a given trial. This function will build the agent
            state, choose an action, receive a reward, and learn if enabled. """
        pass

    def run():
    """ Driving function for running the simulation. 
        Press ESC to close the simulation, or [SPACE] to pause the simulation. """
        pass

if __name__ == '__main__':
    run()